{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ellemcfarlane/Documents/dtu/Perception_AF/Pfas-finalProject/venv0/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Root directory is /Users/ellemcfarlane/Documents/dtu/Perception_AF/Pfas-finalProject\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import List, Tuple, Dict\n",
    "from ultralytics import YOLO\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from deep_sort.application_util import preprocessing\n",
    "from deep_sort.deep_sort import nn_matching\n",
    "from deep_sort.deep_sort.detection import Detection\n",
    "from deep_sort.deep_sort.tracker import Tracker\n",
    "from deep_sort.tools import generate_detections as gdet\n",
    "\n",
    "\n",
    "# own\n",
    "from utils.utils import (get_frames, SEQ_01, SEQ_02, SEQ_03)\n",
    "from utils.deepsort_utils import LABELS_DICT, UNKNOWN_DEFAULT, resize_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deepsort_model_ = './networks/mars-small128.pb' # TODO missing\n",
    "yolo_model_ = '../../models/yolov8s-seg.pt' # TODO missing\n",
    "\n",
    "encoder = gdet.create_box_encoder(deepsort_model_, batch_size=1)\n",
    "_metric = nn_matching.NearestNeighborDistanceMetric(\"cosine\", 0.4, None)\n",
    "tracker = Tracker(_metric, n_init=0)\n",
    "detector = YOLO(yolo_model_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DeepSortObject():\n",
    "    id: int\n",
    "    label: str\n",
    "    confidence: float\n",
    "    xyxy: List[float]\n",
    "    mask: np.ndarray\n",
    "\n",
    "    @property\n",
    "    def tlwh(self):\n",
    "        \"\"\"\n",
    "        Top left corner, width, height representation of bounding box\n",
    "        \"\"\"\n",
    "        top_left_x, top_left_y = self.xyxy[0], self.xyxy[1]\n",
    "        width = self.xyxy[2] - self.xyxy[0]\n",
    "        height = self.xyxy[3] - self.xyxy[1]\n",
    "        return [top_left_x, top_left_y, width, height]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x640 4 persons, 4 bicycles, 124.9ms\n",
      "Speed: 0.5ms preprocess, 124.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 224x640 4 persons, 4 bicycles, 251.8ms\n",
      "Speed: 2.4ms preprocess, 251.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "frames = [(_l, _r) for _l, _r in [get_frames(frame_num_=i, seq_dir_=SEQ_01) for i in range(2)]]\n",
    "detection_results = []\n",
    "\n",
    "for _i_frame, (_frame_l, _frame_r) in enumerate(frames):\n",
    "    # 1. Detect objects with YOLO.\n",
    "    # Output: List of objects (one per detection in frame)\n",
    "    _detections_i = detector(_frame_l, classes=[0, 1, 2])\n",
    "    # _masks_i = resize_masks(masks=_detections_i.masks.data.numpy(),orig_shape=_detections_i.masks.orig_shape)\n",
    "\n",
    "    # boxes = _detections_i[0].boxes\n",
    "    if not _detections_i: print(f\"no detections in frame {_i_frame}\");continue\n",
    "\n",
    "    # detection_results.append(_detections_i) # QUESTION: Need to keep track of ALL detecitons?\n",
    "\n",
    "    dsobjects_i = []\n",
    "    #cls_val = int(box.cls[0])\n",
    "    for _det, _maks in zip(_detections_i.boxes, _masks_i): \n",
    "        cls = int(_det.cls[0])\n",
    "        # NOTE: I'm override id to match \"class_id\" aka 0,1,etc for label\n",
    "        # another note: we can't create the DeepSortObject ahead of time like this\n",
    "        # because later there is no way to match deepsort's track object to these (because for the bounding boxes are slightly diff\n",
    "        # from YOLO's and other tiny details)\n",
    "        # so, instead, we create them dynamically in the deepsort loop like I do below\n",
    "        _dso = DeepSortObject(\n",
    "            id=int(cls), # This changes later with deepsort\n",
    "            label=LABELS_DICT.get(int(cls), UNKNOWN_DEFAULT),\n",
    "            confidence=float(_det.conf[0]),\n",
    "            xyxy = _det.xyxy.tolist()[0],\n",
    "            mask = None\n",
    "            # mask =_maks.astype(bool)\n",
    "        )\n",
    "        \n",
    "        dsobjects_i.append(_dso)\n",
    "\n",
    "    # 2. Pass detections to deepsort\n",
    "\n",
    "    # 2.1 Extract features from detections.\n",
    "    all_bboxes_i = [_dso.xyxy for _dso in dsobjects_i]\n",
    "    features = encoder(_frame_l, all_bboxes_i)\n",
    "\n",
    "    # 2.2 make deepsort detections  from features and objects to feed the tracker\n",
    "    _ds_detections=[]\n",
    "    for _dso, _feat in zip(dsobjects_i, features):\n",
    "        _ds_detections.append(Detection(\n",
    "            tlwh=_dso.tlwh,\n",
    "            feature=_feat,\n",
    "            segmentation=_dso.mask,\n",
    "            class_id=int(_dso.id),\n",
    "            confidence=_dso.confidence))\n",
    "\n",
    "    # 2.3 predict tracks\n",
    "    tracker.predict()\n",
    "    tracker.update(_ds_detections)\n",
    "\n",
    "    # 4. Process tracks\n",
    "    # frame_results = []\n",
    "    # ds_objects is what we should return\n",
    "    ds_objects = {}\n",
    "    occluded_threshold = 2\n",
    "    # process/save track info like bbox, class, etc\n",
    "    for track in tracker.tracks:\n",
    "        # track can be tentative (recently created, needs more evidence aka associations in n_init+1 frames),\n",
    "        # confirmed (associated for n_init+1 or more frames), or deleted (no longer tracked)\n",
    "        # a new object is classified as tentative in the first n_init frames\n",
    "        # https://github.com/nwojke/deep_sort/issues/48\n",
    "        if track.is_confirmed():\n",
    "            # change track bbox to top left, bottom right coordinates.\n",
    "            bbox = list(track.to_tlbr())\n",
    "            # if occluded (aka not detected in past X frames), use previous frame's class for given id\n",
    "            if track.time_since_update > occluded_threshold:\n",
    "                # TODO: we could use this to fill in the \"occluded\" state instead\n",
    "                conf = \"occluded\"\n",
    "            else:\n",
    "                conf = track.get_confidence()\n",
    "            cls = track.get_class()\n",
    "            mask = track.get_segmentation()\n",
    "            # format matches labels.txt\n",
    "            # but we set UNKNOWN_DEFAULT for all values deepsort is not responsible for\n",
    "            # TODO: remove this data since we only care about deepsort objects?\n",
    "            # I only had it here to compare to groundtruth\n",
    "            # data = {\n",
    "            #     \"frame\": _i_frame,\n",
    "            #     \"track_id\": track.track_id,\n",
    "            #     \"type\": cls,\n",
    "            #     \"truncated\": UNKNOWN_DEFAULT,\n",
    "            #     \"occluded\": UNKNOWN_DEFAULT,\n",
    "            #     \"alpha\": UNKNOWN_DEFAULT,\n",
    "            #     \"bbox_left\": int(bbox[0]),\n",
    "            #     \"bbox_top\": int(bbox[1]),\n",
    "            #     \"bbox_right\": int(bbox[2]),\n",
    "            #     \"bbox_bottom\": int(bbox[3]),\n",
    "            #     \"height\": UNKNOWN_DEFAULT,\n",
    "            #     \"width\": UNKNOWN_DEFAULT,\n",
    "            #     \"length\": UNKNOWN_DEFAULT,\n",
    "            #     \"x\": UNKNOWN_DEFAULT,\n",
    "            #     \"y\": UNKNOWN_DEFAULT,\n",
    "            #     \"z\": UNKNOWN_DEFAULT,\n",
    "            #     \"yaw\": UNKNOWN_DEFAULT,\n",
    "            #     \"score\": conf,\n",
    "            # }\n",
    "            # frame_results.append(data)\n",
    "            ds_objects[track.track_id] = DeepSortObject(\n",
    "                id=track.track_id, # This changes later with deepsort\n",
    "                label=LABELS_DICT.get(int(cls), UNKNOWN_DEFAULT),\n",
    "                confidence=float(_det.conf[0]),\n",
    "                xyxy=_det.xyxy.tolist()[0],\n",
    "                mask=_maks.astype(bool)\n",
    "            )\n",
    "            # print(f\"id: {track.track_id}, frame: {frame_idx}, cls: {cls}, box: {bbox}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pedestrian\n",
      "\n",
      "Pedestrian\n",
      "\n",
      "Pedestrian\n",
      "\n",
      "Cyclist\n",
      "\n",
      "Pedestrian\n",
      "\n",
      "Cyclist\n",
      "\n",
      "Cyclist\n",
      "\n",
      "Cyclist\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for obj in ds_objects:\n",
    "    print(ds_objects[obj].label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so nice, this is what we expect: 4 pedestrians, 4 \"cyclists\" aka bicycles but I overwrote the label lol"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End goal\n",
    "function that takes in a pair of left and right frame and spits out a dictionary of `DeepSortObject`s for the objects recognized in the frame_t, with their id's as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_objects(frames:Tuple(np.ndarray)) -> Dict[int, DeepSortObject]:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dsobjects_i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dets_i = detection_results[0]\n",
    "\n",
    "# _det_0 = _dets_i[0]\n",
    "\n",
    "# print(f\"confidences: {_det_0.conf[0]}\")\n",
    "# print(f\"classes: {LABELS_DICT.get(int(_det_0.cls[0]))} ({_det_0.cls[0]})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dets_i = detection_results[0]\n",
    "\n",
    "objects_i = []\n",
    "for _det in _dets_i:\n",
    "    _dso = DeepSortObject()\n",
    "    _dso.id = int(_det.cls[0])\n",
    "    _dso.label = LABELS_DICT.get(int(_dso.id), UNKNOWN_DEFAULT)\n",
    "    _dso.confidence = float(_det.conf[0])\n",
    "    _dso.xyxy = _det.xyxy.tolist()[0]\n",
    "    _dso.mask = None\n",
    "    \n",
    "    objects_i.append(_dso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('venv0': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "878cfb9e7c5aded1d4bf739427e5f0391620946644bd41f9c84683fc740e6717"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
